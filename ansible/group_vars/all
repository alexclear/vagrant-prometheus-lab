apt_key_url: "https://download.docker.com/linux/ubuntu/gpg"
alertmanagers_group_name: "prom-alertmanagers"
alertmanager_advertise_address: "{{ ansible_eth1.ipv4.address }}"
alertmanager_default_receiver: "slack-test"
alertmanager_receivers:
  - name: "slack-test"
    configs:
      slack_configs:
        - channel: "'#vagrant-alerts'"
          send_resolved: "true"
          api_url: "'https://hooks.slack.com/services/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'"
install_kernel_extras_dio: False
ext_prometheus_data_volume: /var/lib/docker-extvols/prometheus/data
ext_prometheus_config_volume: /var/lib/docker-extvols/prometheus/config
nginx_lua_prometheus: True
grafana_admin_user: test
grafana_admin_password: ooZ6ukei
grafana_enable_internal_metrics: True
grafana_prometheus_address: 172.16.137.2
grafana_auto_prometheus_config: True
grafana_auto_dashboards_config: True
nginx_package_name: "nginx-extras"
nginx_extra_conf_options: |
        include /etc/nginx/modules-enabled/*.conf;
nginx_extra_http_options: |
        lua_shared_dict prometheus_metrics 10M;
        lua_package_path "/var/lib/nginx-lua-prometheus/?.lua";
        init_by_lua '
          prometheus = require("prometheus").init("prometheus_metrics")
          metric_requests = prometheus:counter(
            "nginx_http_requests_total", "Number of HTTP requests", {"host", "status"})
          metric_latency = prometheus:histogram(
            "nginx_http_request_duration_seconds", "HTTP request latency", {"host"})
          metric_connections = prometheus:gauge(
            "nginx_http_connections", "Number of HTTP connections", {"state"})
        ';
        log_by_lua '
          metric_requests:inc(1, {ngx.var.server_name, ngx.var.status})
          metric_latency:observe(tonumber(ngx.var.request_time), {ngx.var.server_name})
        ';
prometheus_jobs:
  - name: nodesebpf
    metrics_path: "/metrics"
    targets:
      - host: 172.16.137.2
        port: 9435
      - host: 172.16.137.3
        port: 9435
      - host: 172.16.137.4
        port: 9435
  - name: nodes
    metrics_path: "/metrics"
    targets:
      - host: 172.16.137.2
        port: 9100
      - host: 172.16.137.3
        port: 9100
      - host: 172.16.137.4
        port: 9100
  - name: nginxes
    metrics_path: "/metrics"
    targets:
      - host: 172.16.137.2
        port: 9145
      - host: 172.16.137.3
        port: 9145
      - host: 172.16.137.4
        port: 9145
  - name: docker
    metrics_path: "/metrics"
    targets:
      - host: 172.16.137.2
        port: 9323
grafana_dashboards_grafonnet:
  - file_name: dashboard
    dashboard_name: Nginx
    time_from: "now-3h"
    refresh: "30s"
    tags:
      - nginx
    templates:
      - name: "instance"
        query: "label_values(nginx_http_requests_total, instance)"
        label: "Instance"
        includeAll: "false"
    panels:
      - name: "Reqs rate (on all instances)"
        type: "graph"
        stack: "true"
        fill: 8
        format: "short"
        span: 6
        gridpos_x: 0
        gridpos_y: 0
        gridpos_w: 12
        gridpos_h: 10
        decimals: 2
        min: 0
        max: "null"
        alias_colors: "{}"
        linewidth: 1
        targets:
          - expr: "sum by (instance)(irate(nginx_http_requests_total[5m]))"
            legend_format: !unsafe "{{instance}}"
            format: 'time_series'
            interval_factor: 2
      - name: "Reqs rate (total on $instance)"
        type: "graph"
        stack: "true"
        fill: 1
        format: "short"
        span: 6
        gridpos_x: 12
        gridpos_y: 0
        gridpos_w: 12
        gridpos_h: 10
        decimals: 2
        min: 0
        max: "null"
        alias_colors: "{}"
        linewidth: 1
        targets:
          - expr: 'sum by (instance)(irate(nginx_http_requests_total{instance="$instance"}[5m]))'
            legend_format: !unsafe "{{status}}"
            format: 'time_series'
            interval_factor: 2
      - name: "Reqs rate (by status on $instance)"
        type: "graph"
        stack: "true"
        fill: 10
        format: "short"
        span: 6
        gridpos_x: 0
        gridpos_y: 0
        gridpos_w: 12
        gridpos_h: 10
        decimals: 2
        min: 0
        max: "null"
        alias_colors: "{}"
        linewidth: 1
        targets:
          - expr: 'sum by (status)(irate(nginx_http_requests_total{instance="$instance"}[5m]))'
            legend_format: !unsafe "{{status}}"
            format: 'time_series'
            interval_factor: 2
      - name: "Reqs rate (by host on $instance)"
        type: "graph"
        stack: "true"
        fill: 10
        format: "short"
        span: 6
        gridpos_x: 12
        gridpos_y: 0
        gridpos_w: 12
        gridpos_h: 10
        decimals: 2
        min: 0
        max: "null"
        alias_colors: "{}"
        linewidth: 1
        targets:
          - expr: 'sum by (host)(irate(nginx_http_requests_total{instance="$instance"}[5m]))'
            legend_format: !unsafe "{{host}}"
            format: 'time_series'
            interval_factor: 2
  - file_name: cpu
    dashboard_name: CPU
    time_from: "now-3h"
    refresh: "30s"
    tags:
      - hosts
    templates:
      - name: "instance"
        query: "label_values(node_cpu_seconds_total, instance)"
        label: "Instance"
        includeAll: "false"
    panels:
      - name: "CPU util % on $instance"
        type: "graph"
        stack: "true"
        fill: 10
        format: "percent"
        span: 6
        gridpos_x: 0
        gridpos_y: 0
        gridpos_w: 24
        gridpos_h: 10
        decimals: 2
        min: 0
        max: "null"
        alias_colors: "{}"
        linewidth: 1
        targets:
          - expr: '(avg by (mode)(irate(node_cpu_seconds_total{instance="$instance"}[5m])))*100'
            legend_format: !unsafe "{{mode}}"
            format: 'time_series'
            interval_factor: 2
  - file_name: diskutil
    dashboard_name: "Disk util %"
    time_from: "now-3h"
    refresh: "30s"
    tags:
      - hosts
    templates:
      - name: "instance"
        query: "label_values(node_disk_io_time_seconds_total, instance)"
        label: "Instance"
        includeAll: "false"
    panels:
      - name: "Disk util % on $instance"
        type: "graph"
        stack: "false"
        fill: 0
        format: "percent"
        span: 6
        gridpos_x: 0
        gridpos_y: 0
        gridpos_w: 24
        gridpos_h: 10
        decimals: 2
        min: 0
        max: 100
        alias_colors: '{ "sda": "#70dbed", "sdb": "#bf1b00" }'
        linewidth: 1
        targets:
          - expr: 'irate(node_disk_io_time_seconds_total{instance="$instance"}[5m])*100'
            legend_format: !unsafe "{{device}}"
            format: 'time_series'
            interval_factor: 2
  - file_name: conntrack
    dashboard_name: "Connection tracking"
    time_from: "now-3h"
    refresh: "30s"
    tags:
      - hosts
    templates:
      - name: "instance"
        query: "label_values(node_nf_conntrack_entries, instance)"
        label: "Instance"
        includeAll: "false"
    panels:
      - name: "Connection tracking entries on $instance"
        type: "graph"
        stack: "false"
        fill: 0
        format: "short"
        span: 6
        gridpos_x: 0
        gridpos_y: 0
        gridpos_w: 24
        gridpos_h: 10
        decimals: 2
        min: 0
        max: "null"
        alias_colors: '{ "Nr. of entries": "#e5a8e2" }'
        linewidth: 2
        targets:
          - expr: 'node_nf_conntrack_entries{instance="$instance"}'
            legend_format: !unsafe "Nr. of entries"
            format: 'time_series'
            interval_factor: 2
grafana_dashboards_heatmaps:
  - file_name: nginxlat
    dashboard_name: "Nginx latencies"
    time_from: "now-3h"
    tags:
      - nginx
    templates: []
    panels:
      - name: "Nginx response latencies"
        card_color: "#d683ce"
        decimals: "null"
        format: "short"
        targets:
          - expr: 'sum by (le)(rate(nginx_http_request_duration_seconds_bucket[5m]))'
            legend_format: !unsafe "{{le}}"
  - file_name: nginxlatinstances
    dashboard_name: "Nginx latencies by instance"
    time_from: "now-3h"
    tags:
      - nginx
    templates:
      - name: "instance"
        query: "label_values(nginx_http_request_duration_seconds_bucket, instance)"
        label: "Instance"
        includeAll: "false"
    panels:
      - name: "Nginx response latencies"
        card_color: "#5759e0"
        decimals: "null"
        format: "short"
        targets:
          - expr: 'sum by (le)(rate(nginx_http_request_duration_seconds_bucket{instance=\"$instance\"}[5m]))'
            legend_format: !unsafe "{{le}}"
  - file_name: bioinstancedevices
    dashboard_name: "Block I/O latencies by instance and device"
    time_from: "now-3h"
    refresh: "30s"
    tags:
      - hosts
    templates:
      - name: "instance"
        query: "label_values(ebpf_exporter_bio_latency_seconds_bucket, instance)"
        label: "Instance"
        includeAll: "false"
      - name: "device"
        query: 'label_values(ebpf_exporter_bio_latency_seconds_bucket{instance=\"$instance\"}, device)'
        label: "Device"
        includeAll: "false"
    panels:
      - name: "Block I/O latencies on ($instance, $device)"
        card_color: "#fcf82d"
        format: "s"
        decimals: "1"
        targets:
          - expr: 'sum by (le)(rate(ebpf_exporter_bio_latency_seconds_bucket{instance=\"$instance\",device=\"$device\"}[5m]))'
            legend_format: !unsafe "{{le}}"
